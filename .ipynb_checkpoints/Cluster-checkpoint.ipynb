{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d7e0e2ef604ff5934939026c58d7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>LocalCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from joblib import Parallel\n",
    "from dask import compute, delayed\n",
    "from dask.distributed import Client, LocalCluster \n",
    "cl = LocalCluster(n_workers=4)\n",
    "client = Client(cl)\n",
    "cl\n",
    "# close\n",
    "\n",
    "# note: if this throws an error, close jupyter, run \"ulimit -n 4096\" in terminal, then restart jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data location\n",
    "#location = '/Users/mithras/Documents/_SCHOOL/_Drexel/BUSN 710 - Capstone/Data/Forecasting Project/'\n",
    "location = '/Users/loki/Documents/Data/Forecasting Project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pickle\n",
    "\n",
    "# what data granularity\n",
    "granularity = \"daily\"\n",
    "\n",
    "if granularity == \"daily\":\n",
    "    readdata = pd.read_pickle(location+'peco_daily.pkl.zip')\n",
    "    ids = pd.read_pickle(location+'peco_daily_ids.pkl.zip')\n",
    "elif granularity == \"hourly\":\n",
    "    readdata = pd.read_pickle(location+'peco_hourly.pkl.zip')\n",
    "    ids = pd.read_pickle(location+'peco_hourly_ids.pkl.zip')\n",
    "else:\n",
    "    print(\"Granularity selected was not 'daily' or 'hourly'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DACCOUNTID</th>\n",
       "      <th>DMETERNO</th>\n",
       "      <th>Dt</th>\n",
       "      <th>Use</th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>HighDB</th>\n",
       "      <th>LowDB</th>\n",
       "      <th>AvgHumid</th>\n",
       "      <th>AvgWind</th>\n",
       "      <th>AvgDaytimeCloud</th>\n",
       "      <th>AvgCloud</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80949142571848</td>\n",
       "      <td>610057844548</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.583333</td>\n",
       "      <td>69</td>\n",
       "      <td>49</td>\n",
       "      <td>60.583333</td>\n",
       "      <td>6.791667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80949142571848</td>\n",
       "      <td>610057844548</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.583333</td>\n",
       "      <td>74</td>\n",
       "      <td>53</td>\n",
       "      <td>56.833333</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80949142571848</td>\n",
       "      <td>610057844548</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.791667</td>\n",
       "      <td>74</td>\n",
       "      <td>53</td>\n",
       "      <td>67.791667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80949142571848</td>\n",
       "      <td>610057844548</td>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.166667</td>\n",
       "      <td>76</td>\n",
       "      <td>55</td>\n",
       "      <td>70.791667</td>\n",
       "      <td>6.958333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80949142571848</td>\n",
       "      <td>610057844548</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.958333</td>\n",
       "      <td>81</td>\n",
       "      <td>62</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>10.541667</td>\n",
       "      <td>72.5</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DACCOUNTID      DMETERNO         Dt  Use    AvgTemp  HighDB  LowDB  \\\n",
       "0  80949142571848  610057844548 2017-10-01  0.0  59.583333      69     49   \n",
       "1  80949142571848  610057844548 2017-10-02  0.0  62.583333      74     53   \n",
       "2  80949142571848  610057844548 2017-10-03  0.0  62.791667      74     53   \n",
       "3  80949142571848  610057844548 2017-10-04  0.0  65.166667      76     55   \n",
       "4  80949142571848  610057844548 2017-10-05  0.0  70.958333      81     62   \n",
       "\n",
       "    AvgHumid    AvgWind  AvgDaytimeCloud   AvgCloud  Friday  Monday  Saturday  \\\n",
       "0  60.583333   6.791667             30.0  20.000000       0       0         0   \n",
       "1  56.833333   3.166667              2.5  10.000000       0       1         0   \n",
       "2  67.791667   4.666667             30.0  21.250000       0       0         0   \n",
       "3  70.791667   6.958333             20.0  17.500000       0       0         0   \n",
       "4  68.500000  10.541667             72.5  66.666667       0       0         0   \n",
       "\n",
       "   Sunday  Thursday  Tuesday  Wednesday  Holiday  \n",
       "0       1         0        0          0        0  \n",
       "1       0         0        0          0        0  \n",
       "2       0         0        1          0        0  \n",
       "3       0         0        0          1        0  \n",
       "4       0         1        0          0        0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of operations matters in terms of initial data structure\n",
    "# cluster --> regression, or regression --> cluster?\n",
    "clusterFirst = True\n",
    "\n",
    "if clusterFirst:\n",
    "    # restructure data: drop weather info; transition use into wide format\n",
    "    if granularity == \"daily\":\n",
    "        data = readdata.loc[:, readdata.columns.isin(['DACCOUNTID','DMETERNO','Dt','Use'])]\n",
    "        data = data.pivot_table(values='Use', index=['DACCOUNTID','DMETERNO'], columns='Dt').reset_index()\n",
    "    elif granularity == \"hourly\":\n",
    "        data = readdata.loc[:, readdata.columns.isin(['DACCOUNTID','DMETERNO','Dt','Hour','Use'])]\n",
    "        data = data.pivot_table(values='Use', index=['DACCOUNTID','DMETERNO'], columns=['Dt','Hour']).reset_index()\n",
    "    \n",
    "preserve_order = data.loc[:, data.columns.isin(['DACCOUNTID','DMETERNO'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dt</th>\n",
       "      <th>DACCOUNTID</th>\n",
       "      <th>DMETERNO</th>\n",
       "      <th>2017-10-01 00:00:00</th>\n",
       "      <th>2017-10-02 00:00:00</th>\n",
       "      <th>2017-10-03 00:00:00</th>\n",
       "      <th>2017-10-04 00:00:00</th>\n",
       "      <th>2017-10-05 00:00:00</th>\n",
       "      <th>2017-10-06 00:00:00</th>\n",
       "      <th>2017-10-07 00:00:00</th>\n",
       "      <th>2017-10-08 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-09-21 00:00:00</th>\n",
       "      <th>2018-09-22 00:00:00</th>\n",
       "      <th>2018-09-23 00:00:00</th>\n",
       "      <th>2018-09-24 00:00:00</th>\n",
       "      <th>2018-09-25 00:00:00</th>\n",
       "      <th>2018-09-26 00:00:00</th>\n",
       "      <th>2018-09-27 00:00:00</th>\n",
       "      <th>2018-09-28 00:00:00</th>\n",
       "      <th>2018-09-29 00:00:00</th>\n",
       "      <th>2018-09-30 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>665128346596</td>\n",
       "      <td>4464578359312</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>819252079392</td>\n",
       "      <td>609154378812</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>819288717920</td>\n",
       "      <td>4465122076620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>819880484484</td>\n",
       "      <td>4465122193056</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1284453836940</td>\n",
       "      <td>4464330738752</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Dt     DACCOUNTID       DMETERNO  2017-10-01 00:00:00  2017-10-02 00:00:00  \\\n",
       "0    665128346596  4464578359312                 1.14                 0.00   \n",
       "1    819252079392   609154378812                 0.00                 0.00   \n",
       "2    819288717920  4465122076620                  NaN                  NaN   \n",
       "3    819880484484  4465122193056                 0.00                 1.14   \n",
       "4   1284453836940  4464330738752                 0.00                 0.00   \n",
       "\n",
       "Dt  2017-10-03 00:00:00  2017-10-04 00:00:00  2017-10-05 00:00:00  \\\n",
       "0                  0.00                 0.00                 1.14   \n",
       "1                  0.00                 0.00                 1.14   \n",
       "2                  0.00                 0.00                 0.00   \n",
       "3                  0.00                 1.14                 0.00   \n",
       "4                  1.14                 0.00                 1.14   \n",
       "\n",
       "Dt  2017-10-06 00:00:00  2017-10-07 00:00:00  2017-10-08 00:00:00  \\\n",
       "0                  0.00                  0.0                 0.00   \n",
       "1                  0.00                  0.0                 0.00   \n",
       "2                  1.14                  0.0                 1.14   \n",
       "3                  0.00                  0.0                 1.14   \n",
       "4                  1.14                  0.0                 1.14   \n",
       "\n",
       "Dt         ...           2018-09-21 00:00:00  2018-09-22 00:00:00  \\\n",
       "0          ...                          1.14                 0.00   \n",
       "1          ...                          1.14                 0.00   \n",
       "2          ...                          0.00                 1.14   \n",
       "3          ...                          0.00                 0.00   \n",
       "4          ...                          0.00                 1.14   \n",
       "\n",
       "Dt  2018-09-23 00:00:00  2018-09-24 00:00:00  2018-09-25 00:00:00  \\\n",
       "0                  0.00                 1.14                 0.00   \n",
       "1                  0.00                 1.14                 0.00   \n",
       "2                  0.00                 0.00                 1.14   \n",
       "3                  0.00                 1.14                 0.00   \n",
       "4                  1.14                 0.00                 0.00   \n",
       "\n",
       "Dt  2018-09-26 00:00:00  2018-09-27 00:00:00  2018-09-28 00:00:00  \\\n",
       "0                  1.14                 0.00                 1.14   \n",
       "1                  0.00                 0.00                 0.00   \n",
       "2                  0.00                 1.14                 0.00   \n",
       "3                  0.00                 0.00                 1.14   \n",
       "4                  1.14                 1.14                 1.14   \n",
       "\n",
       "Dt  2018-09-29 00:00:00  2018-09-30 00:00:00  \n",
       "0                  0.00                 0.00  \n",
       "1                  0.00                 0.00  \n",
       "2                  0.00                 1.14  \n",
       "3                  0.00                 0.00  \n",
       "4                  1.14                 0.00  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "# normalize\n",
    "from sklearn import preprocessing \n",
    "\n",
    "data_scaled = data.drop(columns=['DACCOUNTID','DMETERNO'])\n",
    "data_scaled = preprocessing.scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-1e134ad3e2e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mSSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mkmeanModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mkmeanModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mSSE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeanModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    966\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, sample_weight, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy_x\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[0;32m--> 311\u001b[0;31m                     order=order, copy=copy_x)\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 568\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# determine k using elbow method\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "K = range(1,12)\n",
    "SSE = []\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(data_scaled)\n",
    "    kmeanModel.fit(data_scaled)\n",
    "    SSE.append(sum(np.min(cdist(data_scaled, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "\n",
    "# scree plot - find the elbow\n",
    "plt.plot(K, SSE, 'bx-')\n",
    "plt.xlabel('Number of K')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('The Elbow Method Showing the Optimal K (Euclidean)')\n",
    "plt.show()\n",
    "\n",
    "# super awesome visualization and screen plot kernels I came across while doing the NYC taxi fare forcasting project:\n",
    "# https://www.kaggle.com/ashishpatel26/exploration-of-nyc\n",
    "# https://www.kaggle.com/willkoehrsen/a-walkthrough-and-a-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def: PCA\n",
    "    # normalize or not?\n",
    "\n",
    "pca_2cw = PCA(n_components=2, whiten=True)\n",
    "X_pca_1cw = pca_2cw.fit_transform(iris.data)\n",
    "plt.scatter(X_pca_1cw[:,0], X_pca_1cw[:,1], c=iris.target,\n",
    "alpha=0.8, s=60, marker='o', edgecolors='white')\n",
    "plt.show()\n",
    "pca_2cw.explained_variance_ratio_.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize cluster identities using PCA on weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize rate-code identities using PCA on weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append cluster ID to daily/hourly set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LocalCluster.close of LocalCluster('tcp://127.0.0.1:63002', workers=1, ncores=1)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# close dask cluster\n",
    "cl.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
